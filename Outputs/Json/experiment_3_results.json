{
  "experiment": 3,
  "config": {
    "name": "Lower Learning Rate",
    "learning_rate": 5e-05,
    "batch_size": 1,
    "gradient_accumulation_steps": 8,
    "epochs": 3,
    "lora_rank": 64,
    "lora_alpha": 128,
    "lora_dropout": 0.05,
    "warmup_steps": 100,
    "weight_decay": 0.01,
    "lr_scheduler": "cosine"
  },
  "training_time_minutes": 21.760908099015555,
  "final_loss": 0.7057762613796205,
  "metrics": {
    "bleu": 0.040232693310110264,
    "rouge1": 0.12251927165494664,
    "rouge2": 0.0395148938893998,
    "rougeL": 0.08643198659308123,
    "perplexity": 5.307526588439941,
    "avg_response_length": 80.6
  },
  "timestamp": "2026-02-15T04:11:48.309929"
}