{
  "best_experiment": "Extended Training (5 epochs)",
  "best_bleu": 0.0806763668047701,
  "hyperparameter_impacts": {
    "lora_rank": 36.23353655100646,
    "learning_rate": -25.403209118702573,
    "training_duration": 49.58476722426979
  },
  "most_impactful_param": "Training Duration",
  "all_experiments": [
    {
      "name": "Baseline",
      "bleu": 0.053933544372077306,
      "rouge_l": 0.08578533176783332,
      "perplexity": 5.179610252380371,
      "training_time": 10.958308390776317
    },
    {
      "name": "Higher LoRA Rank",
      "bleu": 0.07347557488538722,
      "rouge_l": 0.10180998072125341,
      "perplexity": 4.53145694732666,
      "training_time": 21.825371778011323
    },
    {
      "name": "Lower Learning Rate",
      "bleu": 0.040232693310110264,
      "rouge_l": 0.08643198659308123,
      "perplexity": 5.307526588439941,
      "training_time": 21.760908099015555
    },
    {
      "name": "Extended Training (5 epochs)",
      "bleu": 0.0806763668047701,
      "rouge_l": 0.10985436240638785,
      "perplexity": 3.938335418701172,
      "training_time": 35.83498462438583
    }
  ]
}